{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## Have a quick look at H&M catalogues\n",
    "\n",
    "See https://www.kaggle.com/competitions/h-and-m-personalized-fashion-recommendations/data for more information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Python Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Main CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### Load and easy checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/H&M/articles.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape, df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### Looks quite clean, only missing a few descriptions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved Plotly histograms with better formatting\n",
    "def create_histogram_plotly(df, column, title_suffix=\"\"):\n",
    "    \"\"\"Create a horizontal histogram with improved formatting\"\"\"\n",
    "    fig = px.histogram(\n",
    "        df, \n",
    "        y=column,\n",
    "        title=f'Distribution of {title_suffix or column.replace(\"_\", \" \").title()}',\n",
    "        labels={'count': 'Frequency', column: column.replace('_', ' ').title()},\n",
    "        height=max(400, len(df[column].unique()) * 20),  # Dynamic height based on categories\n",
    "        orientation='h'  # Horizontal orientation for better readability of long names\n",
    "    )\n",
    "    \n",
    "    # Improve layout\n",
    "    fig.update_layout(\n",
    "        xaxis_title=\"Frequency\",\n",
    "        yaxis_title=column.replace('_', ' ').title(),\n",
    "        showlegend=False,\n",
    "        margin=dict(l=200, r=50, t=50, b=50),  # Adjust margins for long labels\n",
    "        font=dict(size=12)\n",
    "    )\n",
    "    \n",
    "    # Sort bars by frequency\n",
    "    fig.update_yaxes(categoryorder=\"total ascending\")\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Your original columns\n",
    "fig1 = create_histogram_plotly(df, 'colour_group_name', 'Colour Groups')\n",
    "fig2 = create_histogram_plotly(df, 'perceived_colour_value_name', 'Perceived Colour Values')\n",
    "\n",
    "# Product-related distributions\n",
    "fig3 = create_histogram_plotly(df, 'product_type_name', 'Product Types')\n",
    "fig4 = create_histogram_plotly(df, 'product_group_name', 'Product Groups')\n",
    "fig5 = create_histogram_plotly(df, 'garment_group_name', 'Garment Groups')\n",
    "\n",
    "# Department and organization\n",
    "fig6 = create_histogram_plotly(df, 'department_name', 'Departments')\n",
    "fig7 = create_histogram_plotly(df, 'section_name', 'Sections')\n",
    "fig8 = create_histogram_plotly(df, 'index_name', 'Index Names')\n",
    "\n",
    "# Appearance-related\n",
    "fig9 = create_histogram_plotly(df, 'graphical_appearance_name', 'Graphical Appearances')\n",
    "fig10 = create_histogram_plotly(df, 'perceived_colour_master_name', 'Master Colour Categories')\n",
    "\n",
    "# Display all additional plots\n",
    "for fig in [fig3, fig4, fig5, fig6, fig7, fig8, fig9, fig10]:\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['colour_group_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"product_type_name\"].value_counts().index.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Ollama tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get images\n",
    "image_paths = Path('../data/h-and-m-personalized-fashion-recommendations/images').rglob('*.jpg')\n",
    "image_list = list(image_paths)\n",
    "print(f\"Found {len(image_list)} images, {image_list[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Display first 25 images in 5x5 grid\n",
    "fig, axes = plt.subplots(5, 5, figsize=(15, 15))\n",
    "axes = axes.flatten()  # Convert 2D array to 1D for easier indexing\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    if i < len(image_list) and i < 25:  # Ensure we don't exceed available images\n",
    "        img = mpimg.imread(str(image_list[i]))\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(f\"{image_list[i].name}\", fontsize=8)  # Optional: show filename\n",
    "        ax.axis('off')  # Remove axes\n",
    "    else:\n",
    "        ax.axis('off')  # Hide empty subplots\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load back with sets intact\n",
    "with open('../results/tags.pkl', 'rb') as f:\n",
    "    CLOTHING_CATEGORIES = pickle.load(f)\n",
    "    \n",
    "CLOTHING_CATEGORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_system_prompt(clothing_categories):\n",
    "    \"\"\"Create system prompt with proper category enforcement and description field.\"\"\"\n",
    "    \n",
    "    prompt = \"\"\"You are a clothing analysis AI. Return ONLY valid JSON, no other text.\n",
    "\n",
    "STRICT RULES: You MUST only use tags from these exact lists and include a description field as a string.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    # Add each category with its exact allowed values\n",
    "    for category, items in clothing_categories.items():\n",
    "        if isinstance(items, (set, list)):\n",
    "            items_str = ', '.join(f'\"{item}\"' for item in sorted(items))\n",
    "            prompt += f'{category.upper()}: [{items_str}]\\n\\n'\n",
    "\n",
    "    prompt += f\"\"\"CRITICAL:\n",
    "- Use ONLY the tags from the list: {list(clothing_categories.keys())}\n",
    "- Each category must be a list of strings\n",
    "- Add a \"description\" field with a short textual description of the clothing in the image\n",
    "- If unsure about a category, use empty list []\n",
    "- Return JSON only, no explanations\n",
    "\n",
    "STRICT: Do not use any keys other than the exact category names provided.\n",
    "Do not use combined or generic keys like \"categories\".\n",
    "Every category must be present, even if empty like [].\n",
    "\"\"\"\n",
    "\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def create_user_prompt():\n",
    "    \"\"\"User prompt asking for JSON with categories and a short description.\"\"\"\n",
    "    return \"\"\"Analyze this clothing image. Return JSON with the 9 categories as lists of strings and a \"description\" field with a concise summary of the clothing. Use only allowed tags. JSON only, no other text.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_json_simple(response_text: str) -> dict:\n",
    "    \"\"\"Just parse JSON as-is, no cleaning\"\"\"\n",
    "    try:\n",
    "        return {\n",
    "            'success': True,\n",
    "            'data': json.loads(response_text)\n",
    "        }\n",
    "    except:\n",
    "        return {\n",
    "            'success': False,\n",
    "            'data': None\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import io\n",
    "import base64\n",
    "\n",
    "def resize_and_encode_image(image_path, max_width=256):\n",
    "    \"\"\"Resize and encode image\"\"\"\n",
    "    image = Image.open(image_path)\n",
    "    if image.width > max_width:\n",
    "        ratio = max_width / image.width\n",
    "        new_height = int(image.height * ratio)\n",
    "        image = image.resize((max_width, new_height), Image.Resampling.LANCZOS)\n",
    "    \n",
    "    buffered = io.BytesIO()\n",
    "    image.save(buffered, format=\"JPEG\")\n",
    "    return base64.b64encode(buffered.getvalue()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import ollama\n",
    "\n",
    "def test_model(model_name: str, encoded_image: str, system_prompt: str, user_prompt: str) -> dict:\n",
    "    \"\"\"Test one model\"\"\"\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        response = ollama.chat(\n",
    "            model=model_name,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt, \"images\": [encoded_image]},\n",
    "            ],\n",
    "        )\n",
    "        \n",
    "        duration = time.time() - start_time\n",
    "        parsed = parse_json_simple(response.message.content)\n",
    "        \n",
    "        return {\n",
    "            \"model\": model_name,\n",
    "            \"duration\": duration,\n",
    "            \"response\": response.message.content,\n",
    "            \"data\": parsed['data'],\n",
    "            \"json_success\": parsed['success']\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"model\": model_name,\n",
    "            \"error\": str(e),\n",
    "            \"data\": None,\n",
    "            \"json_success\": False\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_json_block(response_text):\n",
    "    if \"categories\" in response_text.lower():\n",
    "        print(i)\n",
    "    match = re.search(r'(\\{.*\\})', response_text, re.DOTALL)\n",
    "    if match:\n",
    "        json_str = match.group(1).replace('[\"\"]', '[]').replace('[\"]', '[]').lower()\n",
    "        try:\n",
    "            data = json.loads(json_str)\n",
    "        except json.JSONDecodeError as e:\n",
    "            raise ValueError(f\"Failed to parse JSON: {e}\")\n",
    "    else:\n",
    "        raise ValueError(\"JSON block not found\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_RETRIES = 10\n",
    "\n",
    "from typing import List, Dict\n",
    "\n",
    "def save_results(result, filename):\n",
    "    with open(filename, \"a\", encoding=\"utf-8\") as f:\n",
    "        json_line = json.dumps(result, ensure_ascii=False)\n",
    "        f.write(json_line + \"\\n\")\n",
    "\n",
    "def is_valid_structure(data, expected_keys):\n",
    "    # Check keys exactly match expected, no extras or missing ones\n",
    "    data_keys = set(data.keys())\n",
    "    expected_keys = set(expected_keys)\n",
    "    return data_keys == expected_keys\n",
    "\n",
    "def call_ai_and_validate(model_name, encoded_image, system_prompt, user_prompt, expected_keys):\n",
    "    for attempt in range(MAX_RETRIES):\n",
    "        response_text = test_model(model_name, encoded_image, system_prompt, user_prompt)  \n",
    "        json_data = extract_json_block(response_text[\"response\"])\n",
    "        \n",
    "        if json_data and is_valid_structure(json_data, expected_keys):\n",
    "            return response_text | json_data \n",
    "        else:\n",
    "            print(f\"Invalid response structure on attempt {attempt+1}, retrying...\")\n",
    "    raise ValueError(\"Failed to get valid JSON structure after retries\")\n",
    "\n",
    "def run_analysis_batch(image_paths: List[str], clothing_categories: dict, output_file: str) -> List[dict]:\n",
    "    \"\"\"Run analysis on multiple images with tqdm progress bar\"\"\"\n",
    "    \n",
    "    models = [\"llava:7b\", \"qwen2.5vl:7b\"]\n",
    "    expected_keys = list(CLOTHING_CATEGORIES.keys()) + [\"description\"]\n",
    "    \n",
    "    system_prompt = create_system_prompt(clothing_categories)\n",
    "    user_prompt = create_user_prompt()\n",
    "        \n",
    "    results = []\n",
    "    \n",
    "    for image_path in tqdm(image_paths, desc=\"Processing images\"):\n",
    "        try:\n",
    "            encoded_image = resize_and_encode_image(image_path)\n",
    "            \n",
    "            for model_name in models:\n",
    "                try:\n",
    "                    result = call_ai_and_validate(model_name, encoded_image, system_prompt, user_prompt, expected_keys)\n",
    "                    result[\"image_name\"] = Path(image_path).name\n",
    "                    result[\"image_path\"] = str(image_path)\n",
    "                    result[\"json_success\"] = True\n",
    "                    results.append(result)\n",
    "                except ValueError as e:\n",
    "                    # Max retries reached, log and continue\n",
    "                    result = {\n",
    "                        \"model\": model_name,\n",
    "                        \"image_name\": Path(image_path).name,\n",
    "                        \"image_path\": str(image_path),\n",
    "                        \"error\": f\"Max retries reached: {str(e)}\",\n",
    "                        \"data\": None,\n",
    "                        \"json_success\": False\n",
    "                    }\n",
    "                    results.append(result)\n",
    "                save_results(result, filename=output_file)\n",
    "           \n",
    "        except Exception as e:\n",
    "            \n",
    "            # Handle image processing errors\n",
    "            for model_name in models:\n",
    "                results.append({\n",
    "                    \"model\": model_name,\n",
    "                    \"image_name\": Path(image_path).name,\n",
    "                    \"image_path\": str(image_path),\n",
    "                    \"error\": f\"Image processing error: {str(e)}\",\n",
    "                    \"data\": None,\n",
    "                    \"json_success\": False\n",
    "                })\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_analysis_batch(image_list[:1000], CLOTHING_CATEGORIES, output_file=\"../results/h&m.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mirror",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
